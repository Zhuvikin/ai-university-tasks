{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device is cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Current device is', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.FashionMNIST('data/homework1/', \n",
    "                           download=True, \n",
    "                           train=True, \n",
    "                           transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_set = datasets.FashionMNIST('data/homework1/', \n",
    "                          download=True, \n",
    "                          train=False, \n",
    "                          transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size:  torch.Size([60000, 28, 28])\n",
      "Train data labels:  torch.Size([60000])\n",
      "Test data size:  torch.Size([10000, 28, 28])\n",
      "Test data labels:  torch.Size([10000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuvikin/anaconda3/envs/AIU_ML/lib/python3.7/site-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/Users/zhuvikin/anaconda3/envs/AIU_ML/lib/python3.7/site-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/Users/zhuvikin/anaconda3/envs/AIU_ML/lib/python3.7/site-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/Users/zhuvikin/anaconda3/envs/AIU_ML/lib/python3.7/site-packages/torchvision/datasets/mnist.py:48: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "print('Train data size: ', train_set.train_data.size())\n",
    "print('Train data labels: ', train_set.train_labels.size())\n",
    "\n",
    "print('Test data size: ', test_set.test_data.size())\n",
    "print('Test data labels: ', test_set.test_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 5\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_loader, device, epochs = epochs):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for e in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch, (target, labels) in enumerate(train_loader):\n",
    "            target = target.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the gradients before running the backwprop.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            yhat = model(target)\n",
    "\n",
    "            loss = criterion(yhat, labels)\n",
    "\n",
    "            # Computer all the gradients of the loss in the respect to all learnable params\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weight\n",
    "            \n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if batch % math.ceil(8000 / batch_size) == math.ceil(8000 / batch_size) - 1:\n",
    "                print('Epoch {}, Train loss {}'.format(e, total_loss / 2000))\n",
    "                total_loss = 0\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train loss 0.045375131905078886\n",
      "Epoch 0, Train loss 0.025201572000980377\n",
      "Epoch 0, Train loss 0.02250900074839592\n",
      "Epoch 0, Train loss 0.02062866860628128\n",
      "Epoch 0, Train loss 0.019679408699274065\n",
      "Epoch 0, Train loss 0.018786437667906285\n",
      "Epoch 0, Train loss 0.01779517535865307\n",
      "Epoch 1, Train loss 0.01732957324385643\n",
      "Epoch 1, Train loss 0.01691229233145714\n",
      "Epoch 1, Train loss 0.016797538504004478\n",
      "Epoch 1, Train loss 0.016515687480568884\n",
      "Epoch 1, Train loss 0.015874560214579104\n",
      "Epoch 1, Train loss 0.015959055319428445\n",
      "Epoch 1, Train loss 0.01600893058627844\n",
      "Epoch 2, Train loss 0.015009997375309468\n",
      "Epoch 2, Train loss 0.01591036770492792\n",
      "Epoch 2, Train loss 0.015225421376526356\n",
      "Epoch 2, Train loss 0.013897190295159817\n",
      "Epoch 2, Train loss 0.015044055074453354\n",
      "Epoch 2, Train loss 0.014503111205995083\n",
      "Epoch 2, Train loss 0.014564092881977558\n",
      "Epoch 3, Train loss 0.013944836474955083\n",
      "Epoch 3, Train loss 0.013663594134151935\n",
      "Epoch 3, Train loss 0.013572278261184692\n",
      "Epoch 3, Train loss 0.01340301437675953\n",
      "Epoch 3, Train loss 0.013438302777707576\n",
      "Epoch 3, Train loss 0.013985940769314765\n",
      "Epoch 3, Train loss 0.013568043731153012\n",
      "Epoch 4, Train loss 0.01240202009677887\n",
      "Epoch 4, Train loss 0.012456717260181905\n",
      "Epoch 4, Train loss 0.012781352512538433\n",
      "Epoch 4, Train loss 0.013547000043094158\n",
      "Epoch 4, Train loss 0.012285352319478988\n",
      "Epoch 4, Train loss 0.012901357434689998\n",
      "Epoch 4, Train loss 0.012453108787536622\n"
     ]
    }
   ],
   "source": [
    "model = train_model(NeuralNetwork().to(device), train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataLoader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for target, labels in dataLoader:\n",
    "            target, labels = target.to(device), labels.to(device)\n",
    "            yhat = model(target)\n",
    "            test_loss += F.nll_loss(yhat, labels, reduction='sum').item()\n",
    "            prediction = yhat.argmax(dim=1, keepdim=True)\n",
    "            correct += prediction.eq(labels.view_as(prediction)).sum().item()\n",
    "\n",
    "    print('Test set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(dataLoader.dataset), 100. * correct / len(dataLoader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Accuracy: 8686/10000 (87%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JKERNEL",
   "language": "python",
   "name": "jkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
